{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./Data/YelpReviews.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_text'] = df['review_text'].str.strip('\"') # Remove the quotes from the review text\n",
    "\n",
    "df['text_character_length'] = df['review_text'].str.len() # Calculate the length of the review text\n",
    "\n",
    "df['text_word_count'] = df['review_text'].str.split().str.len() # Calculate the word count of the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens are the smallest units of text that the model can process. They can be words, parts of words, or punctuation marks. For example, the word \"tokenization\" might be split into \"token\" and \"##ization\". It's how AI processes texts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    return len(tokenizer.tokenize(text))\n",
    "\n",
    "df['token_count'] = df['review_text'].apply(count_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_long_text(text, chunk_size=512):\n",
    "    # Tokenize the text\n",
    "    tokens = sentiment_pipeline.tokenizer.tokenize(text)\n",
    "    \n",
    "    # Split into chunks\n",
    "    chunks = [tokens[i:i + chunk_size] for i in range(0, len(tokens), chunk_size)]\n",
    "    \n",
    "    # Analyze each chunk\n",
    "    results = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        chunk_text = sentiment_pipeline.tokenizer.convert_tokens_to_string(chunk)\n",
    "        result = sentiment_pipeline(chunk_text)[0]\n",
    "        results.append(result)\n",
    "    \n",
    "\n",
    "    # Aggregate results\n",
    "    pos_scores = [r['score'] for r in results if r['label'] == 'positive']\n",
    "    neg_scores = [r['score'] for r in results if r['label'] == 'negative']\n",
    "    neu_scores = [r['score'] for r in results if r['label'] == 'neutral']\n",
    "\n",
    "    \n",
    "    pos_avg = sum(pos_scores) / len(pos_scores) if pos_scores else 0\n",
    "    neg_avg = sum(neg_scores) / len(neg_scores) if neg_scores else 0\n",
    "    neu_avg = sum(neu_scores) / len(neu_scores) if neu_scores else 0\n",
    "    \n",
    "    # Determine the dominant sentiment\n",
    "    if pos_avg > neg_avg and pos_avg > neu_avg:\n",
    "        return {\"label\": \"positive\", \"score\": pos_avg}\n",
    "    elif neg_avg > pos_avg and neg_avg > neu_avg:\n",
    "        return {\"label\": \"negative\", \"score\": neg_avg}\n",
    "    else:\n",
    "        return {\"label\": \"neutral\", \"score\": neu_avg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results = df.head(100)['review_text'].apply(lambda x: analyze_long_text(x))\n",
    "sentiment_results\n",
    "sentiment_scores = [result['score'] for result in sentiment_results]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 5))\n",
    "scaled_scores = scaler.fit_transform(np.array(sentiment_scores).reshape(-1, 1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.95190664, 3.85735126, 1.51922227, 4.96481957, 2.06838219,\n",
       "       4.76908126, 4.82740587, 1.80018865, 4.91906629, 4.58837951,\n",
       "       4.991626  , 4.5708714 , 4.84628669, 4.47354908, 2.90531688,\n",
       "       4.30898103, 4.80167933, 4.97980848, 4.94622006, 4.73906554,\n",
       "       4.95177919, 2.77305239, 4.80755595, 4.80813121, 4.67604412,\n",
       "       2.87974708, 2.33921147, 4.98449324, 2.78692121, 2.91878555,\n",
       "       4.87393133, 4.9300944 , 2.74927956, 4.95803471, 2.42187326,\n",
       "       4.90947747, 2.06683209, 4.90559475, 4.93129659, 4.62973395,\n",
       "       4.63044412, 4.84849587, 1.05208631, 4.8886395 , 4.67932115,\n",
       "       4.82213782, 4.73737937, 2.44178289, 5.        , 3.38818925,\n",
       "       4.59366422, 4.78785702, 4.91370351, 4.94624016, 4.87841801,\n",
       "       4.09943705, 1.41233124, 4.93303386, 2.21821852, 4.87527073,\n",
       "       4.83094412, 3.98005104, 1.9813405 , 0.28253744, 2.17975245,\n",
       "       4.69444728, 4.74267613, 4.4788688 , 4.83164855, 3.9661627 ,\n",
       "       4.49953339, 4.28522543, 4.59744417, 1.69211236, 4.26376053,\n",
       "       4.48057621, 4.57033805, 2.67699312, 4.87448362, 0.5555805 ,\n",
       "       4.9480997 , 4.99132746, 4.58558244, 4.73198157, 4.38152525,\n",
       "       4.87650163, 3.34929317, 0.43092816, 4.90027675, 1.48106564,\n",
       "       2.32952621, 0.        , 4.8213708 , 4.28441651, 4.70616203,\n",
       "       4.93324456, 4.65058512, 1.0475158 , 2.68448528, 4.93383474])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'label': 'positive', 'score': 0.9849315881729...\n",
       "1     {'label': 'positive', 'score': 0.8712942004203...\n",
       "2      {'label': 'neutral', 'score': 0.628548264503479}\n",
       "3     {'label': 'positive', 'score': 0.9862722158432...\n",
       "4     {'label': 'neutral', 'score': 0.6855623722076416}\n",
       "                            ...                        \n",
       "95    {'label': 'positive', 'score': 0.9829940795898...\n",
       "96    {'label': 'positive', 'score': 0.9536482095718...\n",
       "97    {'label': 'negative', 'score': 0.5795754194259...\n",
       "98    {'label': 'positive', 'score': 0.7495265603065...\n",
       "99    {'label': 'positive', 'score': 0.9830553531646...\n",
       "Name: review_text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
